{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports used throughout the notebook. \n",
    "# PLEASE INSTALL THE FOLLOWING PACKAGES:\n",
    "from typing import Callable, Dict, List, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from dython import nominal\n",
    "from dython.nominal import associations\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(16,8)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data: pd.DataFrame, categorical_features: List[str], continuous_features: List[str], target_variable: str):\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    # subset df\n",
    "    #df = df[(df[\"Race\"]==\"White\") | (df[\"Race\"]==\"Black\")]\n",
    "    df[\"AgeCategory\"] = df[\"AgeCategory\"].apply(mean_of_age_category)\n",
    "    \n",
    "    # target\n",
    "    target = df[target_variable].values\n",
    "    \n",
    "    df_processed = df[categorical_features + continuous_features].copy() #.copy to avoid \"SettingWithCopyWarning\"\n",
    "\n",
    "    # protected variables\n",
    "    sex = df[\"Sex\"].values\n",
    "    age = df[\"AgeCategory\"].values\n",
    "    race = df[\"Race\"].values\n",
    "    \n",
    "    df_processed = pd.get_dummies(df_processed, prefix=None, prefix_sep='_',\n",
    "                                  dummy_na=False, columns=categorical_features, drop_first=True)\n",
    "\n",
    "    return df_processed, df, target, race\n",
    "\n",
    "def mean_of_age_category(row):\n",
    "    if \"older\" in row:\n",
    "        return 80\n",
    "    else:\n",
    "        return np.mean(list(map(int, row.split(\"-\"))))\n",
    "\n",
    "def describe_df(df, col):\n",
    "    for val in df[col].unique():\n",
    "        print(\"Race: \", val)\n",
    "        display(df[df[col]==val].describe()[['BMI','PhysicalHealth','MentalHealth', 'AgeCategory', 'SleepTime']].T.style.background_gradient(cmap='Blues'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/heart_train.csv')\n",
    "val = pd.read_csv('data/heart_val.csv')\n",
    "test = pd.read_csv('data/heart_test.csv')\n",
    "\n",
    "# Select only rows with black and white race\n",
    "train = train.loc[train['Race'].isin(['White', 'Black'])]\n",
    "val = val.loc[val['Race'].isin(['White', 'Black'])]\n",
    "test = test.loc[test['Race'].isin(['White', 'Black'])]\n",
    "\n",
    "categorical_features = [\n",
    "    \"Smoking\",\n",
    "    \"AlcoholDrinking\",\n",
    "    \"Stroke\",\n",
    "    \"DiffWalking\",\n",
    "    \"Sex\",\n",
    "    \"AgeCategory\",\n",
    "    \"Race\",\n",
    "    \"Diabetic\",\n",
    "    \"PhysicalActivity\",\n",
    "    \"GenHealth\",\n",
    "    \"Asthma\",\n",
    "    \"KidneyDisease\",\n",
    "    \"SkinCancer\"\n",
    "]\n",
    "\n",
    "continuous_features = [\n",
    "    \"BMI\",\n",
    "    \"PhysicalHealth\",\n",
    "    \"MentalHealth\"\n",
    "]\n",
    "\n",
    "target_variable = \"HeartDisease\"\n",
    "\n",
    "train_processed, train_original, train_target, train_race = data_preprocessing(\n",
    "    train, categorical_features=categorical_features,\n",
    "    continuous_features=continuous_features,\n",
    "    target_variable=target_variable)\n",
    "val_processed, val_original, val_target, val_race = data_preprocessing(\n",
    "    val, categorical_features=categorical_features,\n",
    "    continuous_features=continuous_features,\n",
    "    target_variable=target_variable)\n",
    "test_processed, test_original, test_target, test_race = data_preprocessing(\n",
    "    test, categorical_features=categorical_features,\n",
    "    continuous_features=continuous_features,\n",
    "    target_variable=target_variable)\n",
    "\n",
    "y_train, y_val, y_test = train_target, val_target, test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of health indicators for age groups\n",
    "\n",
    "target = \"HeartDisease\"\n",
    "group = \"Race\"\n",
    "subgroup = \"Sex\"\n",
    "indexes = \"AgeCategory\"\n",
    "categoricals = list(set(categorical_features) - set([group, subgroup]) - set([\"AgeCategory\"]))\n",
    "continuous = list(set(continuous_features) - set([\"AgeCategory\"]))\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize= (15, 5), sharey=True)\n",
    "colors = [\"#a6cee3\", \"#1f78b4\", \"#b2df8a\", \"#33a02c\", \"#fb9a99\", \"#e31a1c\", \"#fdbf6f\", \"#ff7f00\", \"#cab2d6\", \"#6a3d9a\"]\n",
    "\n",
    "\n",
    "for i, g in enumerate(train_original[group].unique()):\n",
    "    for c, cat in enumerate(categoricals):\n",
    "        sns.kdeplot(train_original[(train_original[target]==\"Yes\") \n",
    "                               & (train_original[cat]==\"Yes\")\n",
    "                               & (train_original[group]==g)][indexes], alpha=1, shade=False, color=colors[c],\n",
    "               label=cat, ax=axes[i])\n",
    "    axes[i].set_title(f\"Group: {g}\")\n",
    "    axes[i].set_xlabel(\"AgeCategory\")\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "    axes[i].legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    axes[i].set_xlim(0, 100)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"diseases_frequency_white_black.png\", dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "binary_features = [\"Asthma_Yes\", \"KidneyDisease_Yes\", \"Smoking_Yes\", \"Stroke_Yes\", \n",
    "                   \"SkinCancer_Yes\", \"AlcoholDrinking_Yes\", \"PhysicalActivity_Yes\", \"DiffWalking_Yes\"]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14,7), sharey=True)\n",
    "x = np.arange(len(binary_features))\n",
    "width = 0.35\n",
    "\n",
    "for val in train_processed[\"Race_White\"].unique():\n",
    "    no = []\n",
    "    yes = []\n",
    "    \n",
    "    for col in binary_features:\n",
    "        n, y = train_processed[train_processed[\"Race_White\"]==val][col].value_counts(normalize=True).values\n",
    "        no.append(n)\n",
    "        no=[round(i, 2) for i in no]\n",
    "        yes.append(y)\n",
    "        yes=[round(i, 2) for i in yes]\n",
    "    \n",
    "    if val == 1:\n",
    "        rects1 = ax[0].barh(x - width/2, no, width, label='No')\n",
    "        rects2 = ax[0].barh(x + width/2, yes, width, label='Yes')\n",
    "        \n",
    "        # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "        ax[0].set_ylabel('Binary Features')\n",
    "        ax[0].set_xlabel('Percent')\n",
    "\n",
    "        ax[0].set_title('Race: White')\n",
    "        ax[0].set_yticks(x, binary_features)\n",
    "        \n",
    "        ax[0].bar_label(rects1, padding=3)\n",
    "        ax[0].bar_label(rects2, padding=3)\n",
    "    else:\n",
    "        rects1 = ax[1].barh(x - width/2, no,width, label='No')\n",
    "        rects2 = ax[1].barh(x + width/2, yes, width, label='Yes')\n",
    "        \n",
    "        # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "        ax[1].set_title('Race: Black')\n",
    "        ax[1].set_yticks(x, binary_features)\n",
    "        ax[1].set_xlabel('Percent')\n",
    "\n",
    "        \n",
    "        ax[1].bar_label(rects1, padding=3)\n",
    "        ax[1].bar_label(rects2, padding=3)\n",
    "\n",
    "#ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.legend(loc=2, labels=['No', 'Yes'], bbox_to_anchor=(1.02, 1), borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions and classes used in our experiments\n",
    "\n",
    "def equailized_odds(preds: np.ndarray, groups: np.ndarray,\n",
    "                    test: np.ndarray, verbose: bool = False) -> Union[float, Dict]:\n",
    "    \"\"\"\n",
    "    Calculates the equailized odds of a binary classification problem.\n",
    "    preds: predictions of the model\n",
    "    groups: group labels of the test data\n",
    "    test: test data\n",
    "    sum_of_differences: if True, the sum of the differences is returned, else the mean of the differences is returned\n",
    "    verbose: if True, prints the results\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame(list(zip(preds, groups, test)),\n",
    "                      columns=['preds', 'groups', 'test'])\n",
    "\n",
    "    # save all results\n",
    "    all_results = {}\n",
    "\n",
    "    total_class_difference = 0\n",
    "    for target in df['test'].unique():\n",
    "        results = {}\n",
    "        for group in df['groups'].unique():\n",
    "\n",
    "            # get the group and amount of corrects in the group\n",
    "            selection = df.loc[(df['test'] == target) &\n",
    "                               (df['groups'] == group)]\n",
    "            corrects = selection.loc[selection['preds'] == 'Yes']\n",
    "\n",
    "            # if there are no corrects in the group, skip\n",
    "            if len(corrects) == 0:\n",
    "                results[group] = 0\n",
    "                continue\n",
    "\n",
    "            # get the odds ratio\n",
    "            score = round(len(corrects) / len(selection), 3)\n",
    "\n",
    "            # add the score to the results\n",
    "            results[group] = score\n",
    "\n",
    "            if verbose:\n",
    "                print(f'Target [{target}] and group [{group}]: {score} ')\n",
    "\n",
    "        class_differences = abs(results['White'] - results['Black'])\n",
    "\n",
    "        if verbose:\n",
    "            print(results)\n",
    "            print(f'Class differences for class {group}: {class_differences}')\n",
    "\n",
    "        # sum up differences or take average\n",
    "        total_class_difference += class_differences\n",
    "\n",
    "        all_results[target] = results\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Total class difference: {total_class_difference}')\n",
    "\n",
    "    return total_class_difference, all_results\n",
    "\n",
    "class Objective(object):\n",
    "    \"\"\"Objective class used in hyperparameter optimization\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        X_train: np.ndarray,\n",
    "        X_val: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "        group_val: np.ndarray,\n",
    "        evaluation_func: Callable,\n",
    "        run_optim_no_fairness: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray\n",
    "            Training data\n",
    "        X_val : np.ndarray\n",
    "            Validation data\n",
    "        y_train : np.ndarray\n",
    "            Training labels\n",
    "        y_val : np.ndarray\n",
    "            Validation labels\n",
    "        group_val : np.ndarray\n",
    "            Validation group\n",
    "        evaluation_func : Callable\n",
    "            Evaluation function\n",
    "        run_optim_no_fairness : bool, optional\n",
    "            Run optimization without considering fairness, by default False\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.group_val = group_val\n",
    "        self.evaluation_func = evaluation_func,\n",
    "        self.run_optim_no_fairness = run_optim_no_fairness\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        \"\"\"This method is called by Optuna to compute the objective\n",
    "        function.\"\"\"\n",
    "\n",
    "        # Parameter space to optimize\n",
    "        params = {\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\"]),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 20, 50),\n",
    "            \"min_samples_split\": trial.suggest_float(\"min_samples_split\", 1e-5, 0.01),\n",
    "            \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 1e-5, 0.01),\n",
    "        }\n",
    "\n",
    "        # parameters for fitting a model\n",
    "        whitebox_model = DecisionTreeClassifier(\n",
    "            **params, random_state=42).fit(self.X_train, self.y_train)\n",
    "\n",
    "        preds: np.ndarray = whitebox_model.predict(self.X_val)\n",
    "\n",
    "        if self.run_optim_no_fairness:\n",
    "            return metrics.f1_score(self.y_val, preds, labels=[\n",
    "                                    'Yes'], pos_label=\"Yes\")\n",
    "        else:\n",
    "            return self.evaluation_func[0](preds, self.group_val, self.y_val, verbose=False)[\n",
    "                0], metrics.f1_score(self.y_val, preds, labels=['Yes'], pos_label=\"Yes\")\n",
    "\n",
    "def reproject_features(\n",
    "        data: pd.DataFrame, protected_cols: List[str], nonprotected_cols: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    generate a fair representation of nonprotected columns which are independent from any columns in protected_cols\n",
    "\n",
    "    data : pd.DataFrame\n",
    "        dataframe with columns to be projected\n",
    "    protected_cols : List[str]\n",
    "        list of protected columns\n",
    "    nonprotected_cols : List[str]\n",
    "        list of non-protected columns\n",
    "    \"\"\"\n",
    "    # make a copy of data\n",
    "    df: pd.DataFrame = data.copy()\n",
    "    # df is our data\n",
    "    # extract data about protected columns\n",
    "    nonprotect: np.ndarray = df[nonprotected_cols].values\n",
    "    protect: np.ndarray = df[protected_cols].values\n",
    "    # extract data about nonprotected columns\n",
    "    debiased_nonprotect: np.ndarray = df[nonprotected_cols].values\n",
    "    # crease an orthonormal basis\n",
    "    base_protect: np.ndarray = scipy.linalg.orth(protect)\n",
    "\n",
    "    batch_size = 1000\n",
    "\n",
    "    # go through all protected attributes and calculate their contribution to\n",
    "    # the reprojection to the hyperplane\n",
    "    for j in range(debiased_nonprotect.shape[1]):\n",
    "        for index in range(0, data.shape[0], batch_size):\n",
    "            start, stop = index, min(index + batch_size, data.shape[0])\n",
    "            debiased_nonprotect[start:stop,\n",
    "                                j] -= base_protect[start:stop] @ base_protect[start:stop].T @ nonprotect[start:stop, j]\n",
    "    return debiased_nonprotect\n",
    "\n",
    "\n",
    "def reproject_features_w_regul(\n",
    "        data: pd.DataFrame, protected_cols: List[str], nonprotected_cols: List[str], lambda_: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    generate a fair representation of nonprotected columns which are independent from any columns in protected_cols\n",
    "    data: a data frame\n",
    "    protected_cols: list of strings, the protected columns\n",
    "    nonprotected_col: string, all other data columns\n",
    "    lambda_: float number between 0 and 1, 0 means totally fair; 1 means same as raw data\n",
    "    \"\"\"\n",
    "\n",
    "    # run the normal reproject_features function\n",
    "    r: np.ndarray = reproject_features(data, protected_cols, nonprotected_cols)\n",
    "\n",
    "    # extract data about nonprotected variables\n",
    "    nonprotect: np.ndarray = data[nonprotected_cols].values\n",
    "    # standardize columns\n",
    "\n",
    "    return r + lambda_ * (nonprotect - r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading the data as we overwrite the dataframe with the new data\n",
    "train = pd.read_csv('data/heart_train.csv')\n",
    "val = pd.read_csv('data/heart_val.csv')\n",
    "test = pd.read_csv('data/heart_test.csv')\n",
    "\n",
    "# Select only rows with black and white race\n",
    "train = train.loc[train['Race'].isin(['White', 'Black'])]\n",
    "val = val.loc[val['Race'].isin(['White', 'Black'])]\n",
    "test = test.loc[test['Race'].isin(['White', 'Black'])]\n",
    "\n",
    "categorical_features = [\n",
    "    \"Smoking\",\n",
    "    \"AlcoholDrinking\",\n",
    "    \"Stroke\",\n",
    "    \"DiffWalking\",\n",
    "    \"Sex\",\n",
    "    \"AgeCategory\",\n",
    "    \"Race\",\n",
    "    \"Diabetic\",\n",
    "    \"PhysicalActivity\",\n",
    "    \"GenHealth\",\n",
    "    \"Asthma\",\n",
    "    \"KidneyDisease\",\n",
    "    \"SkinCancer\"\n",
    "]\n",
    "\n",
    "continuous_features = [\n",
    "    \"BMI\",\n",
    "    \"PhysicalHealth\",\n",
    "    \"MentalHealth\"\n",
    "]\n",
    "\n",
    "target_variable = \"HeartDisease\"\n",
    "\n",
    "train_processed, train_original, train_target, train_race = data_preprocessing(\n",
    "    train, categorical_features=categorical_features,\n",
    "    continuous_features=continuous_features,\n",
    "    target_variable=target_variable)\n",
    "val_processed, val_original, val_target, val_race = data_preprocessing(\n",
    "    val, categorical_features=categorical_features,\n",
    "    continuous_features=continuous_features,\n",
    "    target_variable=target_variable)\n",
    "test_processed, test_original, test_target, test_race = data_preprocessing(\n",
    "    test, categorical_features=categorical_features,\n",
    "    continuous_features=continuous_features,\n",
    "    target_variable=target_variable)\n",
    "\n",
    "y_train, y_val, y_test = train_target, val_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS MIGHT TAKE A LITTLE WHILE TO RUN FYI.\n",
    "\n",
    "experiment_number = 2 # select 1 or 2\n",
    "\n",
    "if experiment_number == 1:\n",
    "    standardize = True # standardize data\n",
    "    standardize_continuous = True # standardize continuous data only\n",
    "    resample = False # resample data to ensure even distribution of targets\n",
    "    reproject = False # reproject data\n",
    "    lambda_reproject = False # use regularization in reprojection\n",
    "    run_optim_no_fairness = True # If true, run optimization without fairness\n",
    "\n",
    "else:\n",
    "    standardize = True\n",
    "    standardize_continuous = True\n",
    "    resample = True\n",
    "    reproject = False\n",
    "    lambda_reproject = False\n",
    "    run_optim_no_fairness = False\n",
    "\n",
    "if standardize:\n",
    "    if standardize_continuous:\n",
    "        # Scale continuous variables\n",
    "        mean_ = np.mean(train_processed[continuous_features], axis=0)\n",
    "        std_ = np.std(train_processed[continuous_features], ddof=1, axis=0)\n",
    "\n",
    "        train_processed = (\n",
    "            train_processed[continuous_features] - mean_) / std_\n",
    "        val_processed = (val_processed[continuous_features] - mean_) / std_\n",
    "        test_processed = (\n",
    "            test_processed[continuous_features] - mean_) / std_\n",
    "\n",
    "    else:\n",
    "        # Standardize all variables\n",
    "        mean_ = np.mean(train_processed, axis=0)\n",
    "        std_ = np.std(train_processed, ddof=1, axis=0)\n",
    "\n",
    "        train_processed = (train_processed - mean_) / std_\n",
    "        val_processed = (val_processed - mean_) / std_\n",
    "        test_processed = (test_processed - mean_) / std_\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "    if run_optim_no_fairness:\n",
    "        study = optuna.create_study(direction=\"maximize\",\n",
    "                                    sampler=sampler,\n",
    "                                    pruner=optuna.pruners.MedianPruner(\n",
    "                                        n_startup_trials=2, n_warmup_steps=5,\n",
    "                                        interval_steps=3),\n",
    "                                    )\n",
    "\n",
    "    else:\n",
    "        study = optuna.create_study(directions=[\"minimize\", \"maximize\"],\n",
    "                                    sampler=sampler,\n",
    "                                    pruner=optuna.pruners.MedianPruner(\n",
    "                                    n_startup_trials=2, n_warmup_steps=5,\n",
    "                                    interval_steps=3),\n",
    "                                    )\n",
    "\n",
    "    # Do random oversampling to make class distribution even\n",
    "    if resample:\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        train_processed, y_train, = ros.fit_resample(\n",
    "            train_processed, y_train)\n",
    "\n",
    "    # Define objective\n",
    "    objective = Objective(\n",
    "        train_processed,\n",
    "        val_processed,\n",
    "        y_train,\n",
    "        y_val,\n",
    "        val_race,\n",
    "        evaluation_func=equailized_odds,\n",
    "        run_optim_no_fairness=run_optim_no_fairness)\n",
    "\n",
    "    # Make a study to optimize the objective.\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=100,\n",
    "        n_jobs=-1,\n",
    "        show_progress_bar=True)\n",
    "\n",
    "    if run_optim_no_fairness:\n",
    "        print(study.best_trial)\n",
    "\n",
    "        # Get the best parameters\n",
    "        best_params = study.best_trial.params\n",
    "        model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "        model.fit(train_processed, y_train)\n",
    "\n",
    "        val_pred = model.predict(val_processed)\n",
    "        val_pred_proba = model.predict_proba(val_processed)\n",
    "        test_pred = model.predict(test_processed)\n",
    "        test_pred_proba = model.predict_proba(test_processed)\n",
    "\n",
    "    else:\n",
    "        fig = optuna.visualization.plot_pareto_front(\n",
    "            study, target_names=[\"EO\", \"F1\"])\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading the data as we overwrite the dataframe with the new data\n",
    "standardize = True\n",
    "standardize_continuous = False\n",
    "resample = True\n",
    "reproject = True\n",
    "lambda_reproject = False\n",
    "run_optim_no_fairness = False\n",
    "\n",
    "if reproject or lambda_reproject:\n",
    "    assert standardize == True, 'Reprojecting requires standardizing'\n",
    "\n",
    "train = pd.read_csv('data/heart_train.csv')\n",
    "val = pd.read_csv('data/heart_val.csv')\n",
    "test = pd.read_csv('data/heart_test.csv')\n",
    "\n",
    "# Select only rows with black and white race\n",
    "train = train.loc[train['Race'].isin(['White', 'Black'])]\n",
    "val = val.loc[val['Race'].isin(['White', 'Black'])]\n",
    "test = test.loc[test['Race'].isin(['White', 'Black'])]\n",
    "\n",
    "categorical_features = [\n",
    "    \"Smoking\",\n",
    "    \"AlcoholDrinking\",\n",
    "    \"Stroke\",\n",
    "    \"DiffWalking\",\n",
    "    \"Sex\",\n",
    "    \"AgeCategory\",\n",
    "    \"Race\",\n",
    "    \"Diabetic\",\n",
    "    \"PhysicalActivity\",\n",
    "    \"GenHealth\",\n",
    "    \"Asthma\",\n",
    "    \"KidneyDisease\",\n",
    "    \"SkinCancer\"\n",
    "]\n",
    "\n",
    "continuous_features = [\n",
    "    \"BMI\",\n",
    "    \"PhysicalHealth\",\n",
    "    \"MentalHealth\"\n",
    "]\n",
    "\n",
    "target_variable = \"HeartDisease\"\n",
    "\n",
    "train_processed, train_original, train_target, train_race = data_preprocessing(\n",
    "    train, categorical_features=categorical_features,\n",
    "    continuous_features=continuous_features,\n",
    "    target_variable=target_variable)\n",
    "val_processed, val_original, val_target, val_race = data_preprocessing(\n",
    "    val, categorical_features=categorical_features,\n",
    "    continuous_features=continuous_features,\n",
    "    target_variable=target_variable)\n",
    "test_processed, test_original, test_target, test_race = data_preprocessing(\n",
    "    test, categorical_features=categorical_features,\n",
    "    continuous_features=continuous_features,\n",
    "    target_variable=target_variable)\n",
    "\n",
    "y_train, y_val, y_test = train_target, val_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS MIGHT TAKE EVEN LONGER THAN EXPERIMENT 1 and 2 AS THE REPROJECTION TAKES A LONG TIME\n",
    "\n",
    "# Do random oversampling to make class distribution even\n",
    "if resample:\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    train_processed, y_train, = ros.fit_resample(\n",
    "        train_processed, y_train)\n",
    "\n",
    "protected_cols = ['Race_White']\n",
    "nonprotected_cols = [\n",
    "    f for f in train_processed if f not in protected_cols]\n",
    "\n",
    "lambda_values = np.linspace(0, 1, 25)\n",
    "\n",
    "param_grid = {'criterion': 'gini', \n",
    "            'max_depth': 30, \n",
    "            'min_samples_split': 0.008791657968284442, \n",
    "            'min_samples_leaf': 2.5756722034438575e-05}\n",
    "\n",
    "results_f1 = {}\n",
    "results_eo = {}\n",
    "results_class = {\n",
    "    'TPR_White': [],\n",
    "    'FPR_White': [],\n",
    "    'TPR_Black': [],\n",
    "    'FPR_Black': []}\n",
    "\n",
    "for i in tqdm(lambda_values, desc='Lambda'):\n",
    "\n",
    "    #reprojection\n",
    "    train_processed_r = reproject_features_w_regul(\n",
    "        train_processed,\n",
    "        protected_cols=protected_cols,\n",
    "        nonprotected_cols=nonprotected_cols,\n",
    "        lambda_=i)\n",
    "\n",
    "    val_processed_r = reproject_features_w_regul(\n",
    "        val_processed,\n",
    "        protected_cols=protected_cols,\n",
    "        nonprotected_cols=nonprotected_cols,\n",
    "        lambda_=i)\n",
    "\n",
    "    test_processed_r = reproject_features_w_regul(\n",
    "        test_processed,\n",
    "        protected_cols=protected_cols,\n",
    "        nonprotected_cols=nonprotected_cols,\n",
    "        lambda_=i)\n",
    "\n",
    "    # Fit model\n",
    "    whitebox_model = DecisionTreeClassifier(\n",
    "        **param_grid, random_state=42).fit(train_processed_r, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = whitebox_model.predict(val_processed_r)\n",
    "\n",
    "    # Calculate EO and F1 scores\n",
    "    results_f1[i] = metrics.f1_score(\n",
    "        y_val, y_pred, labels=['Yes'], pos_label=\"Yes\")\n",
    "    results_eo[i] = equailized_odds(y_pred, val_race, y_val)[0]\n",
    "\n",
    "    # Save scores\n",
    "    all_res = equailized_odds(y_pred, val_race, y_val)[1]\n",
    "    results_class[\"TPR_White\"].append(all_res[\"Yes\"]['White'])\n",
    "    results_class[\"FPR_White\"].append(all_res[\"No\"]['White'])\n",
    "    results_class[\"TPR_Black\"].append(all_res[\"Yes\"]['Black'])\n",
    "    results_class[\"FPR_Black\"].append(all_res[\"No\"]['Black'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "fig.suptitle(\"Fairness and performance metrics for different lambda values\", fontsize='x-large')\n",
    "# adjust the subplots, i.e. leave more space at the top to accomodate the additional titles\n",
    "fig.subplots_adjust(top=0.78)  \n",
    "\n",
    "# plot FPR and TPR\n",
    "ax[0].plot(lambda_values, results_class[\"TPR_White\"], label='TPR White', alpha=0.6, marker='o')\n",
    "ax[0].plot(lambda_values, results_class[\"TPR_Black\"], label='TPR Black', alpha=0.6, marker='x')\n",
    "ax[0].plot(lambda_values, results_class[\"FPR_White\"], label='FPR White', alpha=0.6, marker='v')\n",
    "ax[0].plot(lambda_values, results_class[\"FPR_Black\"], label='FPR Black', alpha=0.6, marker='*')\n",
    "ax[0].set_xlabel('Lambda')\n",
    "ax[0].set_ylabel('FPR/TPR')\n",
    "ax[0].legend(loc = 'upper left')\n",
    "ax[0].set_title('FPR and TPR for the protected groups')\n",
    "\n",
    "# Plot the results f1\n",
    "ax[1].plot(lambda_values, results_f1.values(), label='F1', alpha=0.6, marker='o')\n",
    "ax[1].set_xlabel('Lambda')\n",
    "ax[1].set_ylabel('F1')\n",
    "ax[1].legend(loc = 'upper left')\n",
    "ax[1].set_title('F1 score')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances and SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data and predict on test set\n",
    "standardize = True\n",
    "standardize_continuous = True\n",
    "resample = True\n",
    "reproject = False\n",
    "lambda_reproject = False\n",
    "run_optim_no_fairness = False\n",
    "\n",
    "train = pd.read_csv('data/heart_train.csv')\n",
    "val = pd.read_csv('data/heart_val.csv')\n",
    "test = pd.read_csv('data/heart_test.csv')\n",
    "\n",
    "# Select only rows with black and white race\n",
    "train = train.loc[train['Race'].isin(['White', 'Black'])]\n",
    "val = val.loc[val['Race'].isin(['White', 'Black'])]\n",
    "test = test.loc[test['Race'].isin(['White', 'Black'])]\n",
    "\n",
    "categorical_features = [\n",
    "    \"Smoking\",\n",
    "    \"AlcoholDrinking\",\n",
    "    \"Stroke\",\n",
    "    \"DiffWalking\",\n",
    "    \"Sex\",\n",
    "    \"AgeCategory\",\n",
    "    \"Race\",\n",
    "    \"Diabetic\",\n",
    "    \"PhysicalActivity\",\n",
    "    \"GenHealth\",\n",
    "    \"Asthma\",\n",
    "    \"KidneyDisease\",\n",
    "    \"SkinCancer\"\n",
    "]\n",
    "\n",
    "continuous_features = [\n",
    "    \"BMI\",\n",
    "    \"PhysicalHealth\",\n",
    "    \"MentalHealth\"\n",
    "]\n",
    "\n",
    "target_variable = \"HeartDisease\"\n",
    "\n",
    "train_processed, train_original, train_target, train_race = data_preprocessing(\n",
    "    train, categorical_features=categorical_features,\n",
    "    continuous_features=continuous_features,\n",
    "    target_variable=target_variable)\n",
    "val_processed, val_original, val_target, val_race = data_preprocessing(\n",
    "    val, categorical_features=categorical_features,\n",
    "    continuous_features=continuous_features,\n",
    "    target_variable=target_variable)\n",
    "test_processed, test_original, test_target, test_race = data_preprocessing(\n",
    "    test, categorical_features=categorical_features,\n",
    "    continuous_features=continuous_features,\n",
    "    target_variable=target_variable)\n",
    "\n",
    "y_train, y_val, y_test = train_target, val_target, test_target\n",
    "\n",
    "if standardize:\n",
    "    if standardize_continuous:\n",
    "        # Scale continuous variables\n",
    "        mean_ = np.mean(train_processed[continuous_features], axis=0)\n",
    "        std_ = np.std(train_processed[continuous_features], ddof=1, axis=0)\n",
    "\n",
    "        train_processed[continuous_features] = (\n",
    "            train_processed[continuous_features] - mean_) / std_\n",
    "        val_processed[continuous_features] = (val_processed[continuous_features] - mean_) / std_\n",
    "        test_processed[continuous_features] = (\n",
    "            test_processed[continuous_features] - mean_) / std_\n",
    "\n",
    "    else:\n",
    "        # Standardize all variables\n",
    "        mean_ = np.mean(train_processed, axis=0)\n",
    "        std_ = np.std(train_processed, ddof=1, axis=0)\n",
    "\n",
    "        train_processed = (train_processed - mean_) / std_\n",
    "        val_processed = (val_processed - mean_) / std_\n",
    "        test_processed = (test_processed - mean_) / std_\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "# Do random oversampling to make class distribution even\n",
    "if resample:\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    train_processed, y_train, = ros.fit_resample(\n",
    "        train_processed, y_train)\n",
    "\n",
    "best_params_exp2 = {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 0.008791657968284442, 'min_samples_leaf': 2.5756722034438575e-05}\n",
    "\n",
    "model = DecisionTreeClassifier(**best_params_exp2)\n",
    "model.fit(train_processed, y_train)\n",
    "\n",
    "val_pred = model.predict(val_processed)\n",
    "val_pred_proba = model.predict_proba(val_processed)\n",
    "test_pred = model.predict(test_processed)\n",
    "test_pred_proba = model.predict_proba(test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "print('Feature importances')\n",
    "weights = model.feature_importances_\n",
    "feats_names = model.feature_names_in_\n",
    "sorted_importance = list(zip(weights.tolist(), feats_names.tolist()))\n",
    "sorted_importance.sort(key = lambda x: x[0], reverse=True)\n",
    "sorted_importance[:10]\n",
    "\n",
    "feature_importances = {}\n",
    "\n",
    "feature_names = continuous_features + categorical_features\n",
    "\n",
    "for feature in feature_names:\n",
    "    feature_importances[feature] = []\n",
    "    for feature_impotrance in sorted_importance:\n",
    "        if feature in feature_impotrance[1]:\n",
    "            feature_importances[feature].append(feature_impotrance[0])\n",
    "    \n",
    "feature_importances = {k: round(np.sum(v), 5) for k, v in feature_importances.items()}\n",
    "feature_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for feat, imp in feature_importances:\n",
    "    print(f'{feat} has summed importance {imp}')\n",
    "\n",
    "feats = [feat for feat, imp in feature_importances[:5]]\n",
    "vals = [imp for feat, imp in feature_importances[:5]]\n",
    "y_pos = np.arange(len(feats))\n",
    "fig, ax = plt.subplots()\n",
    "v = ax.barh(y_pos, vals, align='center')\n",
    "ax.set_yticks(y_pos, labels=feats)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Importance (Gini)')\n",
    "#ax.set_title('How fast do you want to go today?')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAPLEY values\n",
    "explainer = shap.TreeExplainer(model, train_processed, model_output=\"probability\")\n",
    "shap_values = explainer.shap_values(test_processed)\n",
    "shap.summary_plot(shap_values[1], test_processed, feature_names=train_processed.columns, max_display=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalized odds at post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "def map_array(arr:np.ndarray):\n",
    "    d = {\"No\":0, \"Yes\":1}\n",
    "    \n",
    "    return np.array(list(map(lambda x: d[x], arr)))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def check_lengths(*arrays):\n",
    "    \"\"\"\n",
    "    Check that all arrays have the same lenght.\n",
    "    Parameters\n",
    "    ----------\n",
    "    *arrays : list or tuple of input objects.\n",
    "        Objects that will be checked.\n",
    "    \"\"\"\n",
    "    lengths = [len(X) for X in arrays if X is not None]\n",
    "    uniques = np.unique(lengths)\n",
    "    if len(uniques) > 1:\n",
    "        message = \"Input arrays should all be the same length.\"\n",
    "        raise ValueError(message)\n",
    "\n",
    "\n",
    "def check_binaries(*arrays):\n",
    "    \"\"\"\n",
    "    Check that all values in the arrays are 0s or 1s.\n",
    "    Parameters\n",
    "    ----------\n",
    "    *arrays : list or tuple of input objects.\n",
    "        Objects that will be checked.\n",
    "    \"\"\"\n",
    "    values = [set(X) for X in arrays if X is not None]\n",
    "    all_valid = all(v.issubset({0, 1}) for v in values)\n",
    "    if not all_valid:\n",
    "        message = \"Input arrays should only contain 0s and/or 1s.\"\n",
    "        raise ValueError(message)\n",
    "\n",
    "    \n",
    "def perf_measure(y_actual:np.ndarray, y_hat:np.ndarray):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "            tp += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "            fp += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "            tn += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "            fn += 1\n",
    "            \n",
    "    tp = tp / (tp + fn)\n",
    "    fp = fp / (tn + fp)\n",
    "    tn = tn / (tn + fp)\n",
    "    fn = fn / (tp + fn)\n",
    "\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "\n",
    "def perf_measure(y_actual:np.ndarray, y_hat:np.ndarray):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "            tp += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "            fp += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "            tn += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "            fn += 1\n",
    "            \n",
    "    tp = tp / (tp + fn)\n",
    "    fp = fp / (tn + fp)\n",
    "    tn = tn / (tn + fp)\n",
    "    fn = fn / (tp + fn)\n",
    "\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def classification_report(y_true, y_pred, A) -> str:\n",
    "    \"\"\"\n",
    "    String showing the true positive, false\n",
    "    positive, true negatve and false negative rate \n",
    "    for each group.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : 1d array of binaries\n",
    "        Ground truth (correct) target values.\n",
    "    y_pred : 1d array of binaries\n",
    "        Estimated targets as returned by a classifier.\n",
    "    groups: 1d array\n",
    "        Labels for the different groups.\n",
    "    \"\"\"\n",
    "    check_lengths(y_true, y_pred, A)\n",
    "    check_binaries(y_true, y_pred)\n",
    "    groups = np.unique(A)\n",
    "    header = \"{:<30}{:^6}{:^6}{:^6}{:^6}\".format(\"A\", \"TPR\", \"FPR\", \"TNR\", \"FNR\")\n",
    "    row_fmt = \"{:<30}{:^6.2f}{:^6.2f}{:^6.2f}{:^6.2f}\"\n",
    "    lines = [header, \"-\" * len(header)]\n",
    "    for group in groups:\n",
    "        y_true_g = y_true[A == group]\n",
    "        y_pred_g = y_pred[A == group]\n",
    "        tp, fp, tn, fn = perf_measure(y_true_g, y_pred_g)\n",
    "        lines.append(row_fmt.format(group, tp, fp, tn, fn))\n",
    "\n",
    "    tp, fp, tn, fn = perf_measure(y_true, y_pred)\n",
    "    lines.append(row_fmt.format(\"All\", tp, fp, tn, fn))\n",
    "    report = \"\\n\".join(lines)\n",
    "    \n",
    "    return report\n",
    "\n",
    "def evaluate(y_target, y_pred, y_race):\n",
    "    print(classification_report(y_target, y_pred))\n",
    "    print(classification_report(y_target, y_pred, y_race))\n",
    "    print(confusion_matrix(y_target, y_pred, normalize='true', labels=[1,0]))\n",
    "\n",
    "def equalized_odds(preds, groups, test):\n",
    "    df = pd.DataFrame(list(zip(preds, groups, test)), columns=['preds', 'groups', 'test'])\n",
    "    targets = df['test'].unique()\n",
    "    groups = df['groups'].unique()\n",
    "    labels = []\n",
    "    y = []\n",
    "    \n",
    "    \n",
    "    for target in targets:\n",
    "        temp_labels = []\n",
    "        temp_y = []\n",
    "        for group in groups:\n",
    "            selection = df.loc[(df['test'] == target) & (df['groups'] == group)]\n",
    "            corrects = selection.loc[selection['preds'] == target]\n",
    "            score = round(len(corrects) / len(selection), 3) #how many correct out of all for this target and group\n",
    "            temp_labels.append(f'T: {target}, G: {group}')\n",
    "            temp_y.append(score)\n",
    "        labels.append(temp_labels)\n",
    "        y.append(temp_y)\n",
    "    \n",
    "\n",
    "    \n",
    "    # PLOTTING\n",
    "    fig, ax = plt.subplots(figsize=(6,5), sharey=True)\n",
    "    \n",
    "    x = np.arange(len(groups))  # the label locations\n",
    "    x = np.array([i*2 for i in x])\n",
    "    width = 0.5\n",
    "    \n",
    "    rects1 = ax.bar(x - width/2, y[0], width, label='No') #0\n",
    "    rects2 = ax.bar(x + width/2, y[1], width, label='Yes') #1\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Scores by group and target')\n",
    "    ax.set_xticks(x, groups)\n",
    "    ax.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "    ax.bar_label(rects1, padding=3)\n",
    "    ax.bar_label(rects2, padding=3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def find_thresholds(parameters, i, fpr_goal=0.6):\n",
    "    threshold = parameters[\"threshold\"][i]\n",
    "    fpr = parameters[\"fpr\"][i]\n",
    "    \n",
    "    idx = np.argmin(abs(fpr_goal - parameters[\"fpr\"][i]))\n",
    "    threshold = parameters[\"threshold\"][i][idx]\n",
    "    \n",
    "    return threshold, idx\n",
    "\n",
    "\n",
    "def plot_roc_curve(y_race:np.ndarray, y_target:np.ndarray, y_pred_proba:np.ndarray):\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    parameters = {\"fpr\": [], \"tpr\": [], \"threshold\": []}\n",
    "\n",
    "    for race in np.unique(y_race):\n",
    "        y_score = y_pred_proba[y_race==race]\n",
    "        fpr, tpr, threshold = roc_curve(y_target[y_race==race], y_score[:, 1], drop_intermediate=False)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        ax.plot(\n",
    "            fpr,\n",
    "            tpr,\n",
    "            lw=1,\n",
    "            label=f\"ROC curve {race} (area = %0.2f)\" % roc_auc)\n",
    "        parameters[\"fpr\"].append(fpr)\n",
    "        parameters[\"tpr\"].append(tpr)\n",
    "        parameters[\"threshold\"].append(threshold)\n",
    "    plt.xlabel('fpr', fontsize=12)\n",
    "    plt.ylabel('tpr', fontsize=12, rotation=0)\n",
    "    \n",
    "    return fig, ax, parameters\n",
    "\n",
    "def recalculate_predictions(val_race, val_pred_proba, white_threshold, black_threshold):\n",
    "    # Re-calculate predictions using new thresholds\n",
    "\n",
    "    y_pred_fair = list()\n",
    "    for race, proba in zip(val_race, val_pred_proba[:,1]):\n",
    "        if race == \"White\":\n",
    "            y_pred_fair.append(1 if proba >= white_threshold else 0)\n",
    "        elif race == \"Black\":\n",
    "            y_pred_fair.append(1 if proba >= black_threshold else 0)\n",
    "    y_pred_fair = np.array(y_pred_fair)\n",
    "    \n",
    "    return y_pred_fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_target = map_array(val_target)\n",
    "val_pred = map_array(val_pred)\n",
    "test_target = map_array(test_target)\n",
    "test_pred = map_array(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_exp1 = {'criterion': 'gini', 'max_depth': 29, 'min_samples_split': 0.0015208435967915194, 'min_samples_leaf': 0.00010984751659357859}\n",
    "\n",
    "model = DecisionTreeClassifier(**best_params_exp1, random_state=42)\n",
    "model.fit(train_processed, y_train)\n",
    "\n",
    "val_pred = model.predict(val_processed)\n",
    "val_pred_proba = model.predict_proba(val_processed)\n",
    "test_pred = model.predict(test_processed)\n",
    "test_pred_proba = model.predict_proba(test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "fig, ax, parameters = plot_roc_curve(val_race, val_target, val_pred_proba)\n",
    "\n",
    "fpr_goal = 0.6\n",
    "threshold_black, idx_b = find_thresholds(parameters, 0, fpr_goal) #0=black\n",
    "threshold_White, idx_w = find_thresholds(parameters, 1, fpr_goal) #1=white\n",
    "p1 = parameters[\"fpr\"][0][idx_b], parameters[\"tpr\"][0][idx_b]\n",
    "\n",
    "ax.scatter(p1[0], p1[1], s=50, color = 'green')\n",
    "ax.annotate(text = f'Thresholds:\\nBlack: {round(threshold_black, 3)}, White: {round(threshold_White, 3)}', xy = (p1[0]+0.01, p1[1]-0.1), size=10, color = 'black')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_exp2 = {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 0.008791657968284442, 'min_samples_leaf': 2.5756722034438575e-05}\n",
    "\n",
    "model = DecisionTreeClassifier(**best_params_exp2)\n",
    "model.fit(train_processed, y_train)\n",
    "\n",
    "val_pred = model.predict(val_processed)\n",
    "val_pred_proba = model.predict_proba(val_processed)\n",
    "test_pred = model.predict(test_processed)\n",
    "test_pred_proba = model.predict_proba(test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "fig, ax, parameters = plot_roc_curve(val_race, val_target, val_pred_proba)\n",
    "\n",
    "fpr_goal = 0.6\n",
    "threshold_black, idx_b = find_thresholds(parameters, 0, fpr_goal) #0=black\n",
    "threshold_White, idx_w = find_thresholds(parameters, 1, fpr_goal) #1=white\n",
    "p1 = parameters[\"fpr\"][0][idx_b], parameters[\"tpr\"][0][idx_b]\n",
    "\n",
    "ax.scatter(p1[0], p1[1], s=50, color = 'green')\n",
    "ax.annotate(text = f'Thresholds:\\nBlack: {round(threshold_black, 3)}, White: {round(threshold_White, 3)}', xy = (p1[0]+0.01, p1[1]-0.1), size=10, color = 'black')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fe278f9a6b4c7c39f79c5a146ddabdd722ab5b9bb9979420363c779acb74017"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('fair')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
