{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# df = pd.read_csv(\"data/heart_2020_cleaned.csv\")\n",
    "# train, val = train_test_split(df, test_size=0.3, random_state=42, stratify=df[\"HeartDisease\"])\n",
    "# val, test = train_test_split(val, test_size=0.5, random_state=42, stratify=val[\"HeartDisease\"])\n",
    "# train.to_csv(\"data/heart_train.csv\", index=False)\n",
    "# val.to_csv(\"data/heart_val.csv\", index=False)\n",
    "# test.to_csv(\"data/heart_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/heart_train.csv')\n",
    "val = pd.read_csv('data/heart_val.csv')\n",
    "test = pd.read_csv('data/heart_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "\n",
    "categorical_features = [\n",
    "    \"Smoking\",\n",
    "    \"AlcoholDrinking\",\n",
    "    \"Stroke\",\n",
    "    \"DiffWalking\",\n",
    "    \"Sex\",\n",
    "    \"AgeCategory\",\n",
    "    \"Race\",\n",
    "    \"Diabetic\",\n",
    "    \"PhysicalActivity\",\n",
    "    \"GenHealth\",\n",
    "    \"Asthma\",\n",
    "    \"KidneyDisease\",\n",
    "    \"SkinCancer\"\n",
    "]\n",
    "\n",
    "continuos_features = [\n",
    "    \"BMI\",\n",
    "    \"PhysicalHealth\",\n",
    "    \"MentalHealth\"\n",
    "]\n",
    "\n",
    "target_variable = \"HeartDisease\"\n",
    "\n",
    "def data_preprocessing(data: pd.DataFrame, categorical_features: List[str], continuous_features: List[str], target_variable: str):\n",
    "\n",
    "    df = data.copy()\n",
    "\n",
    "    # protected variables\n",
    "    sex = df[\"Sex\"].values\n",
    "    age = df[\"AgeCategory\"].values\n",
    "    race = df[\"Race\"].values\n",
    "\n",
    "    # target\n",
    "    target = df[target_variable].values\n",
    "\n",
    "    df_processed = df[categorical_features + continuous_features]\n",
    "    df_processed = pd.get_dummies(df_processed, prefix=None, prefix_sep='_', dummy_na=False, columns=categorical_features, drop_first=True)\n",
    "\n",
    "    return df_processed, df, target, sex, age, race\n",
    "\n",
    "#df_processed, df_original, target, sex, age, race = data_preprocessing(df, categorical_features=categorical_features, continuous_features=continuos_features, target_variable=target_variable)\n",
    "train_processed, train_original, train_target, train_sex, train_age, train_race = data_preprocessing(train, categorical_features=categorical_features, continuous_features=continuos_features, target_variable=target_variable)\n",
    "val_processed, val_original, val_target, val_sex, val_age, val_race = data_preprocessing(val, categorical_features=categorical_features, continuous_features=continuos_features, target_variable=target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just renaming stuff\n",
    "# X_train, X_val = train_processed.values, val_processed.values\n",
    "y_train, y_val = train_target, val_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness metric function\n",
    "def equailized_odds(preds, groups, test):\n",
    "    print('Equalized Odds')\n",
    "    df = pd.DataFrame(list(zip(preds, groups, test)), columns=['preds', 'groups', 'test'])\n",
    "    labels = []\n",
    "    y = []\n",
    "    total_class_difference = 0\n",
    "    for target in df['test'].unique():\n",
    "        for group in df['groups'].unique():\n",
    "            selection = df.loc[(df['test'] == target) & (df['groups'] == group)]\n",
    "            corrects = selection.loc[selection['preds'] == True]\n",
    "            score = round(len(corrects) / len(selection), 3)\n",
    "            print(f'Target [{target}] and group [{group}]: {score} ')\n",
    "            labels.append(f'T: {target}, G: {group}')\n",
    "            y.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train whitebox model\n",
    "\n",
    "# Scale continuous variables\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = ColumnTransformer([('scaler', StandardScaler(), continuos_features)], remainder='passthrough')\n",
    "\n",
    "# Whitebox model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# whitebox_model = Pipeline(steps=[('scaler', scaler), ('clf', DecisionTreeClassifier(min_samples_split = 0.01, min_samples_leaf= 0.01, max_features=\"auto\", max_depth = 5, criterion = \"gini\", random_state = 42))])\n",
    "# # whitebox_model = Pipeline(steps=[('scaler', scaler), ('clf', DecisionTreeClassifier(random_state = 42))])\n",
    "\n",
    "# whitebox_model.fit(X_train, y_train)\n",
    "# y_pred_whitebox = whitebox_model.predict(X_val)\n",
    "# y_pred_proba_whitebox = whitebox_model.predict_proba(X_val)\n",
    "\n",
    "# print(classification_report(y_val, y_pred_whitebox))\n",
    "\n",
    "# # plot tree\n",
    "# plt.figure(figsize=(25,20))  # set plot size (denoted in inches)\n",
    "# tree.plot_tree(whitebox_model['clf'], fontsize=9, feature_names=df_processed.columns)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agm/projects/algorithmic_fairness/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, List\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "import optuna\n",
    "\n",
    "optuna.logging.set_verbosity(1)\n",
    "\n",
    "class Objective(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X_train: np.ndarray,\n",
    "        X_val: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "        evaluation_func: Callable,\n",
    "    ):\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.evaluation_func = evaluation_func\n",
    "\n",
    "    def __call__(self, trial) -> float:\n",
    "        \"\"\"This method is called by Optuna to compute the objective\n",
    "        function.\"\"\"\n",
    "        # Initialize general hyper parameters\n",
    "\n",
    "        params = {\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 15, step = 2),\n",
    "            \"min_samples_split\": trial.suggest_loguniform(\"min_samples_split\", 1e-3, 0.01),\n",
    "            \"min_samples_leaf\": trial.suggest_loguniform(\"min_samples_leaf\", 1e-3, 0.01),\n",
    "        }\n",
    "\n",
    "        # parameters for fitting a model\n",
    "        whitebox_model = DecisionTreeClassifier(**params, random_state=42).fit(self.X_train, self.y_train)\n",
    "\n",
    "\n",
    "        preds: np.ndarray = whitebox_model.predict(self.X_val)\n",
    "\n",
    "        return self.evaluation_func(preds, self.y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-20 17:13:57,310]\u001b[0m A new study created in memory with name: no-name-154f7b3e-c2e9-437b-87ff-c67f5ed70b7a\u001b[0m\n",
      "/home/agm/projects/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.\n",
      "  warnings.warn(\n",
      "/home/agm/projects/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py:80: UserWarning: Progress bar only supports serial execution (`n_jobs=1`).\n",
      "  warnings.warn(\"Progress bar only supports serial execution (`n_jobs=1`).\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# Run optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Scaling\n",
    "# Scale continuous variables\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = ColumnTransformer([('scaler', StandardScaler(), continuos_features)], remainder='passthrough')\n",
    "X_train = scaler.fit_transform(train_processed)\n",
    "X_val = scaler.transform(val_processed)\n",
    "\n",
    "# Define objective\n",
    "objective = Objective(X_train, X_val, y_train, y_val, metrics.accuracy_score)\n",
    "\n",
    "# Make a study to optimize the objective.\n",
    "study.optimize(objective, n_trials=5, n_jobs = -1, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "\n",
    "# Checking for correlation between variables\n",
    "from dython import nominal\n",
    "\n",
    "data_test = train_original.copy()\n",
    "\n",
    "# Encode the object as an enumerated type or categorical variable.\n",
    "data_test[categorical_features] = data_test[categorical_features].apply(lambda x : pd.factorize(x)[0])\n",
    "nominal.associations(data_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4168ca1474844f3f5fca761e685cf164ea20722acc5773b61bcc07160dedfd10"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
