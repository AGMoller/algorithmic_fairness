{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn import metrics, tree\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# df = pd.read_csv(\"data/heart_2020_cleaned.csv\")\n",
    "# train, val = train_test_split(df, test_size=0.3, random_state=42, stratify=df[\"HeartDisease\"])\n",
    "# val, test = train_test_split(val, test_size=0.5, random_state=42, stratify=val[\"HeartDisease\"])\n",
    "# train.to_csv(\"data/heart_train.csv\", index=False)\n",
    "# val.to_csv(\"data/heart_val.csv\", index=False)\n",
    "# test.to_csv(\"data/heart_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/heart_train.csv')\n",
    "val = pd.read_csv('data/heart_val.csv')\n",
    "test = pd.read_csv('data/heart_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "\n",
    "categorical_features = [\n",
    "    \"Smoking\",\n",
    "    \"AlcoholDrinking\",\n",
    "    \"Stroke\",\n",
    "    \"DiffWalking\",\n",
    "    \"Sex\",\n",
    "    \"AgeCategory\",\n",
    "    \"Race\",\n",
    "    \"Diabetic\",\n",
    "    \"PhysicalActivity\",\n",
    "    \"GenHealth\",\n",
    "    \"Asthma\",\n",
    "    \"KidneyDisease\",\n",
    "    \"SkinCancer\"\n",
    "]\n",
    "\n",
    "continuos_features = [\n",
    "    \"BMI\",\n",
    "    \"PhysicalHealth\",\n",
    "    \"MentalHealth\"\n",
    "]\n",
    "\n",
    "target_variable = \"HeartDisease\"\n",
    "\n",
    "def data_preprocessing(data: pd.DataFrame, categorical_features: List[str], continuous_features: List[str], target_variable: str):\n",
    "\n",
    "    df = data.copy()\n",
    "\n",
    "    # protected variables\n",
    "    sex = df[\"Sex\"].values\n",
    "    age = df[\"AgeCategory\"].values\n",
    "    race = df[\"Race\"].values\n",
    "\n",
    "    # target\n",
    "    target = df[target_variable].values\n",
    "\n",
    "    df_processed = df[categorical_features + continuous_features]\n",
    "    df_processed = pd.get_dummies(df_processed, prefix=None, prefix_sep='_', dummy_na=False, columns=categorical_features, drop_first=True)\n",
    "\n",
    "    return df_processed, df, target, sex, age, race\n",
    "\n",
    "#df_processed, df_original, target, sex, age, race = data_preprocessing(df, categorical_features=categorical_features, continuous_features=continuos_features, target_variable=target_variable)\n",
    "train_processed, train_original, train_target, train_sex, train_age, train_race = data_preprocessing(train, categorical_features=categorical_features, continuous_features=continuos_features, target_variable=target_variable)\n",
    "val_processed, val_original, val_target, val_sex, val_age, val_race = data_preprocessing(val, categorical_features=categorical_features, continuous_features=continuos_features, target_variable=target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just renaming stuff\n",
    "# X_train, X_val = train_processed.values, val_processed.values\n",
    "y_train, y_val = train_target, val_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Fairness metric function\n",
    "import itertools\n",
    "\n",
    "def equailized_odds(preds: np.ndarray, groups: np.ndarray, test: np.ndarray, sum_of_differences: bool = False, verbose: bool = False):\n",
    "    \"\"\"\n",
    "    Calculates the equailized odds of a binary classification problem.\n",
    "    preds: predictions of the model\n",
    "    groups: group labels of the test data\n",
    "    test: test data\n",
    "    sum_of_differences: if True, the sum of the differences is returned, else the mean of the differences is returned\n",
    "    verbose: if True, prints the results\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame(list(zip(preds, groups, test)), columns=['preds', 'groups', 'test'])\n",
    "    \n",
    "    total_class_difference = 0\n",
    "    for target in df['test'].unique():\n",
    "        results = {}\n",
    "        for group in df['groups'].unique():\n",
    "            \n",
    "            # get the group and amount of corrects in the group\n",
    "            selection = df.loc[(df['test'] == target) & (df['groups'] == group)]\n",
    "            corrects = selection.loc[selection['preds'] == \"Yes\"]\n",
    "    \n",
    "            # if there are no corrects in the group, skip\n",
    "            if len(corrects) == 0 or len(selection) == 0:\n",
    "                if target == 'Yes':\n",
    "                    results[group] = 0\n",
    "                else:\n",
    "                    results[group] = 1\n",
    "                continue\n",
    "\n",
    "            # get the odds ratio\n",
    "            score = round(len(corrects) / len(selection), 3)\n",
    "\n",
    "            # add the score to the results\n",
    "            results[group] = score\n",
    "\n",
    "            if verbose:\n",
    "                print(f'Target [{target}] and group [{group}]: {score} ')\n",
    "    \n",
    "        if verbose:\n",
    "            print(results)\n",
    "        group_combinations = list(itertools.combinations(list(results.keys()), 2))\n",
    "    \n",
    "        # save differences between groups (pairwise)\n",
    "        class_differences = 0\n",
    "    \n",
    "        # for each combination of groups\n",
    "        for combination in group_combinations:\n",
    "            if target == 'Yes':\n",
    "                difference = abs(results[combination[0]] - results[combination[1]])\n",
    "            else:\n",
    "                difference = abs((1 - results[combination[0]]) - (1 - results[combination[1]]))\n",
    "                \n",
    "            class_differences += difference\n",
    "\n",
    "        # sum up differences or take average\n",
    "        if sum_of_differences:\n",
    "            total_class_difference += class_differences\n",
    "        else:\n",
    "            total_class_difference += class_differences / len(group_combinations)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Total class difference: {total_class_difference}')\n",
    "\n",
    "    return total_class_difference\n",
    "\n",
    "preds = [0,1,1,1,1]\n",
    "groups = [\"A\", \"A\", \"B\", \"B\", \"C\"]\n",
    "test = [0,0,1,1,1]\n",
    "\n",
    "print(equailized_odds(preds, groups, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'No': 43695, 'Yes': 4274})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.93      0.93      0.93     43863\n",
      "         Yes       0.24      0.25      0.25      4106\n",
      "\n",
      "    accuracy                           0.87     47969\n",
      "   macro avg       0.59      0.59      0.59     47969\n",
      "weighted avg       0.87      0.87      0.87     47969\n",
      "\n",
      "Target [No] and group [White]: 0.075 \n",
      "Target [No] and group [Black]: 0.082 \n",
      "Target [No] and group [Other]: 0.085 \n",
      "Target [No] and group [Asian]: 0.055 \n",
      "Target [No] and group [Hispanic]: 0.06 \n",
      "Target [No] and group [American Indian/Alaskan Native]: 0.076 \n",
      "{'White': 0.075, 'Black': 0.082, 'Other': 0.085, 'Asian': 0.055, 'Hispanic': 0.06, 'American Indian/Alaskan Native': 0.076}\n",
      "Target [Yes] and group [White]: 0.254 \n",
      "Target [Yes] and group [Black]: 0.236 \n",
      "Target [Yes] and group [Other]: 0.27 \n",
      "Target [Yes] and group [Asian]: 0.214 \n",
      "Target [Yes] and group [Hispanic]: 0.246 \n",
      "Target [Yes] and group [American Indian/Alaskan Native]: 0.256 \n",
      "{'White': 0.254, 'Black': 0.236, 'Other': 0.27, 'Asian': 0.214, 'Hispanic': 0.246, 'American Indian/Alaskan Native': 0.256}\n",
      "Total class difference: 0.03766666666666663\n",
      "0.03766666666666663\n"
     ]
    }
   ],
   "source": [
    "# Train whitebox model\n",
    "\n",
    "# Scale continuous variables\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = ColumnTransformer([('scaler', StandardScaler(), continuos_features)], remainder='passthrough')\n",
    "\n",
    "# Whitebox model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scaler = ColumnTransformer(\n",
    "    [('scaler', StandardScaler(), continuos_features)], remainder='passthrough')\n",
    "    \n",
    "# whitebox_model = Pipeline(steps=[('scaler', scaler), ('clf', DecisionTreeClassifier(min_samples_split = 0.01, min_samples_leaf= 0.01, max_features=\"auto\", max_depth = 5, criterion = \"gini\", random_state = 42))])\n",
    "whitebox_model = Pipeline(steps=[('scaler', scaler), ('clf', DecisionTreeClassifier(random_state = 42))])\n",
    "\n",
    "whitebox_model.fit(train_processed, y_train)\n",
    "y_pred_whitebox = whitebox_model.predict(val_processed)\n",
    "y_pred_proba_whitebox = whitebox_model.predict_proba(val_processed)\n",
    "\n",
    "print(Counter(y_pred_whitebox))\n",
    "\n",
    "print(classification_report(y_val, y_pred_whitebox))\n",
    "\n",
    "print(equailized_odds(y_pred_whitebox, val_race, y_val, verbose=True))\n",
    "\n",
    "# # plot tree\n",
    "# plt.figure(figsize=(25,20))  # set plot size (denoted in inches)\n",
    "# tree.plot_tree(whitebox_model['clf'], fontsize=9, feature_names=df_processed.columns)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(1)\n",
    "\n",
    "\n",
    "class Objective(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X_train: np.ndarray,\n",
    "        X_val: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "        group_val: np.ndarray,\n",
    "        evaluation_func: Callable,\n",
    "    ):\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.group_val = group_val\n",
    "        self.evaluation_func = evaluation_func\n",
    "\n",
    "    def __call__(self, trial) -> float:\n",
    "        \"\"\"This method is called by Optuna to compute the objective\n",
    "        function.\"\"\"\n",
    "        # Initialize general hyper parameters\n",
    "\n",
    "        params = {\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 29, step=2),\n",
    "            #\"min_samples_split\": trial.suggest_loguniform(\"min_samples_split\", 1e-3, 0.01),\n",
    "            \"min_samples_split\": trial.suggest_float(\"min_samples_split\", 1e-5, 0.01),\n",
    "            #\"min_samples_leaf\": trial.suggest_loguniform(\"min_samples_leaf\", 1e-3, 0.01),\n",
    "            \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 1e-5, 0.01),\n",
    "        }\n",
    "\n",
    "        # parameters for fitting a model\n",
    "        whitebox_model = DecisionTreeClassifier(\n",
    "            **params, random_state=42).fit(self.X_train, self.y_train)\n",
    "\n",
    "        preds: np.ndarray = whitebox_model.predict(self.X_val)\n",
    "\n",
    "        return self.evaluation_func(preds, self.group_val, self.y_val)\n",
    "        #return self.evaluation_func(preds, self.y_val, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 17:08:25,915]\u001b[0m A new study created in memory with name: no-name-1c236705-c3f0-4f37-bdb5-40a45bf2ff31\u001b[0m\n",
      "/Users/hrmussa/Insync/andersgiovanni@gmail.com/Google Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.\n",
      "  warnings.warn(\n",
      "/Users/hrmussa/Insync/andersgiovanni@gmail.com/Google Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py:80: UserWarning: Progress bar only supports serial execution (`n_jobs=1`).\n",
      "  warnings.warn(\"Progress bar only supports serial execution (`n_jobs=1`).\")\n",
      "\u001b[32m[I 2022-05-21 17:08:27,622]\u001b[0m Trial 7 finished with value: 0.03193333333333334 and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 0.008719801929350643, 'min_samples_leaf': 0.006551562615591968}. Best is trial 7 with value: 0.03193333333333334.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:28,005]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 0.006301935819350953, 'min_samples_leaf': 0.008342981502092133}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:28,356]\u001b[0m Trial 4 finished with value: 0.036800000000000006 and parameters: {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 0.008507881031711725, 'min_samples_leaf': 0.004638591917101736}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:28,405]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 0.006224160366336614, 'min_samples_leaf': 0.009047543777758533}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:28,435]\u001b[0m Trial 2 finished with value: 0.03193333333333334 and parameters: {'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 0.008466534267205983, 'min_samples_leaf': 0.00639964299207575}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:28,800]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 29, 'min_samples_split': 0.0008134687749041489, 'min_samples_leaf': 0.008848328283876763}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:28,810]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 0.0005664868633606777, 'min_samples_leaf': 0.0069643780107997945}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:28,928]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 0.00462929157607347, 'min_samples_leaf': 0.00946504720301695}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:29,704]\u001b[0m Trial 11 finished with value: 0.029933333333333336 and parameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 0.0036415589094374754, 'min_samples_leaf': 0.0004018856258163829}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:29,723]\u001b[0m Trial 8 finished with value: 0.03193333333333334 and parameters: {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 0.002009545835453074, 'min_samples_leaf': 0.0049833309012974085}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:30,193]\u001b[0m Trial 9 finished with value: 0.017133333333333334 and parameters: {'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 0.0009255930971583008, 'min_samples_leaf': 0.000450760689493043}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:30,429]\u001b[0m Trial 10 finished with value: 0.036800000000000006 and parameters: {'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 0.007066572918775818, 'min_samples_leaf': 0.0025205749394514383}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:30,659]\u001b[0m Trial 14 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 0.007187486670226997, 'min_samples_leaf': 0.008012246459951498}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:30,781]\u001b[0m Trial 15 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 0.0023324227842988505, 'min_samples_leaf': 0.007252732541820792}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:31,125]\u001b[0m Trial 12 finished with value: 0.02526666666666667 and parameters: {'criterion': 'entropy', 'max_depth': 17, 'min_samples_split': 0.0004497770421838874, 'min_samples_leaf': 0.000888972679801227}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:31,479]\u001b[0m Trial 13 finished with value: 0.016199999999999996 and parameters: {'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 0.0017229742256676599, 'min_samples_leaf': 0.00015494686324289195}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:31,731]\u001b[0m Trial 16 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 0.0004757021990937149, 'min_samples_leaf': 0.009508241603247652}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:31,913]\u001b[0m Trial 17 finished with value: 0.02993333333333334 and parameters: {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 0.003973888218143468, 'min_samples_leaf': 0.0022718249443077227}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:31,932]\u001b[0m Trial 18 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 0.00362810744219872, 'min_samples_leaf': 0.009773859799082154}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:32,087]\u001b[0m Trial 19 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 0.0034127806589778465, 'min_samples_leaf': 0.009886710505219574}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:32,741]\u001b[0m Trial 20 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 0.004045875601957043, 'min_samples_leaf': 0.009856433969429774}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:32,791]\u001b[0m Trial 21 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 23, 'min_samples_split': 0.004451310265184584, 'min_samples_leaf': 0.009773931866687714}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:33,231]\u001b[0m Trial 22 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 23, 'min_samples_split': 0.004402145715639744, 'min_samples_leaf': 0.009820641251804398}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:33,511]\u001b[0m Trial 24 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 23, 'min_samples_split': 0.0040646773714923985, 'min_samples_leaf': 0.007899936408243826}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:33,519]\u001b[0m Trial 23 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 23, 'min_samples_split': 0.004177653299959091, 'min_samples_leaf': 0.009662033322338531}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:34,060]\u001b[0m Trial 26 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 0.009836705884390687, 'min_samples_leaf': 0.009562318068092188}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:34,073]\u001b[0m Trial 25 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 0.00993021344943053, 'min_samples_leaf': 0.009813667013520625}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:34,561]\u001b[0m Trial 27 finished with value: 0.036800000000000006 and parameters: {'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 0.009956195790792972, 'min_samples_leaf': 0.00385685072289744}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:34,688]\u001b[0m Trial 28 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 0.003172966540274177, 'min_samples_leaf': 0.007753564642667769}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:34,885]\u001b[0m Trial 29 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 0.005293701800921392, 'min_samples_leaf': 0.007836414000983092}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:34,944]\u001b[0m Trial 30 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 0.0053542313653687215, 'min_samples_leaf': 0.007913021782036442}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:35,557]\u001b[0m Trial 31 finished with value: 0.03193333333333334 and parameters: {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 0.005163603408703322, 'min_samples_leaf': 0.0058445394529360204}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:35,608]\u001b[0m Trial 32 finished with value: 0.03193333333333334 and parameters: {'criterion': 'gini', 'max_depth': 29, 'min_samples_split': 0.0053309200400050456, 'min_samples_leaf': 0.005618028603648007}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:35,719]\u001b[0m Trial 33 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 0.005290208771079996, 'min_samples_leaf': 0.007774565575483705}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:35,800]\u001b[0m Trial 35 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 0.0052784582946649354, 'min_samples_leaf': 0.008038457714570641}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:35,814]\u001b[0m Trial 34 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 0.005608814865543431, 'min_samples_leaf': 0.007782348494372734}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:36,860]\u001b[0m Trial 37 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 29, 'min_samples_split': 0.009905902014128781, 'min_samples_leaf': 0.008827701572534676}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:36,915]\u001b[0m Trial 36 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 0.008998834131824555, 'min_samples_leaf': 0.008705015510638178}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:36,948]\u001b[0m Trial 38 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 0.009240103788945788, 'min_samples_leaf': 0.008853506104639558}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:37,572]\u001b[0m Trial 39 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 0.00296182669630947, 'min_samples_leaf': 0.007065052990740948}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:38,029]\u001b[0m Trial 43 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 29, 'min_samples_split': 0.006246123441668915, 'min_samples_leaf': 0.00869650915137125}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:38,031]\u001b[0m Trial 41 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 0.0028938583088395447, 'min_samples_leaf': 0.007167583614059402}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:38,096]\u001b[0m Trial 40 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 0.006143769457066556, 'min_samples_leaf': 0.00879432014191258}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:38,115]\u001b[0m Trial 42 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 29, 'min_samples_split': 0.006091576332223955, 'min_samples_leaf': 0.008612319568551189}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:38,954]\u001b[0m Trial 44 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 0.00604634708928644, 'min_samples_leaf': 0.007050665511102444}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:38,991]\u001b[0m Trial 45 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 0.004451735163563374, 'min_samples_leaf': 0.007123340905947986}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:39,033]\u001b[0m Trial 46 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 17, 'min_samples_split': 0.004585181814870794, 'min_samples_leaf': 0.009123445460299298}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:39,536]\u001b[0m Trial 47 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 0.004734745826550819, 'min_samples_leaf': 0.00927652349425567}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:40,030]\u001b[0m Trial 50 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 0.004502361950499549, 'min_samples_leaf': 0.009266803595403755}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:40,037]\u001b[0m Trial 48 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 0.004240241645128246, 'min_samples_leaf': 0.009325955568358258}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:40,116]\u001b[0m Trial 49 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 0.004626946326648846, 'min_samples_leaf': 0.009254560555777858}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:40,460]\u001b[0m Trial 51 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 0.004607064577385058, 'min_samples_leaf': 0.009242326672621473}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:40,964]\u001b[0m Trial 52 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 0.008024895953890773, 'min_samples_leaf': 0.009276336145376094}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:41,247]\u001b[0m Trial 53 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 0.007005280733221337, 'min_samples_leaf': 0.009329647670048034}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:41,289]\u001b[0m Trial 54 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 0.007849179207919409, 'min_samples_leaf': 0.009195547757137554}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:41,338]\u001b[0m Trial 55 finished with value: 0.03193333333333334 and parameters: {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 0.007995697264563116, 'min_samples_leaf': 0.006218758734745908}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:42,060]\u001b[0m Trial 56 finished with value: 0.03193333333333334 and parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 0.007232891598910648, 'min_samples_leaf': 0.006252419326662969}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:42,127]\u001b[0m Trial 57 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 0.007172167938655622, 'min_samples_leaf': 0.007568799012262701}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:42,178]\u001b[0m Trial 58 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 0.007076333955175431, 'min_samples_leaf': 0.007599087709627533}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:42,231]\u001b[0m Trial 59 finished with value: 0.03193333333333334 and parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 0.007356552347035769, 'min_samples_leaf': 0.006394908351532452}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:42,259]\u001b[0m Trial 60 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 0.005617426858008329, 'min_samples_leaf': 0.007627891192535628}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:42,491]\u001b[0m Trial 62 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 0.009549812146690111, 'min_samples_leaf': 0.008141332915387335}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:42,513]\u001b[0m Trial 61 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 0.005664150488619251, 'min_samples_leaf': 0.007633012716885942}. Best is trial 3 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-05-21 17:08:42,606]\u001b[0m Trial 63 finished with value: 0.03193333333333334 and parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 0.009566555016508334, 'min_samples_leaf': 0.0066222467909836475}. Best is trial 3 with value: 0.0.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hrmussa/Insync/andersgiovanni@gmail.com/Google Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/anders.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/anders.ipynb#ch0000009?line=13'>14</a>\u001b[0m objective \u001b[39m=\u001b[39m Objective(X_train, X_val, y_train, y_val, val_race, equailized_odds)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/anders.ipynb#ch0000009?line=14'>15</a>\u001b[0m \u001b[39m#objective = Objective(X_train_resampled, X_val, y_train_resampled, y_val, val_race, metrics.f1_score)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/anders.ipynb#ch0000009?line=15'>16</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/anders.ipynb#ch0000009?line=16'>17</a>\u001b[0m \u001b[39m# Make a study to optimize the objective.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/anders.ipynb#ch0000009?line=17'>18</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/anders.ipynb#ch0000009?line=19'>20</a>\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/anders.ipynb#ch0000009?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(best_params)\n",
      "File \u001b[0;32m~/Insync/andersgiovanni@gmail.com/Google Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=391'>392</a>\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=392'>393</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=393'>394</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=394'>395</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=395'>396</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=396'>397</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=397'>398</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=399'>400</a>\u001b[0m _optimize(\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=400'>401</a>\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=401'>402</a>\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=402'>403</a>\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=403'>404</a>\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=404'>405</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=405'>406</a>\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=406'>407</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=407'>408</a>\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=408'>409</a>\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/study.py?line=409'>410</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Insync/andersgiovanni@gmail.com/Google Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py:103\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py?line=99'>100</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py?line=101'>102</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(futures) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m n_jobs:\n\u001b[0;32m--> <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py?line=102'>103</a>\u001b[0m     completed, futures \u001b[39m=\u001b[39m wait(futures, return_when\u001b[39m=\u001b[39;49mFIRST_COMPLETED)\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py?line=103'>104</a>\u001b[0m     \u001b[39m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/hrmussa/Insync/andersgiovanni%40gmail.com/Google%20Drive/kds/2sem/algorithmic_fairness/exam_project/algorithmic_fairness/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py?line=104'>105</a>\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m completed:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py:305\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py?line=300'>301</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[1;32m    <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py?line=302'>303</a>\u001b[0m     waiter \u001b[39m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py?line=304'>305</a>\u001b[0m waiter\u001b[39m.\u001b[39;49mevent\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py?line=305'>306</a>\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fs:\n\u001b[1;32m    <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py?line=306'>307</a>\u001b[0m     \u001b[39mwith\u001b[39;00m f\u001b[39m.\u001b[39m_condition:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=555'>556</a>\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=556'>557</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=557'>558</a>\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=558'>559</a>\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=299'>300</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=300'>301</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=301'>302</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=302'>303</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Cellar/python%403.8/3.8.12_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=303'>304</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "# Scaling\n",
    "# Scale continuous variables\n",
    "scaler = ColumnTransformer(\n",
    "    [('scaler', StandardScaler(), continuos_features)], remainder='passthrough')\n",
    "X_train = scaler.fit_transform(train_processed)\n",
    "X_val = scaler.transform(val_processed)\n",
    "\n",
    "# ros = RandomOverSampler(random_state =42)\n",
    "# X_train_resampled , y_train_resampled , = ros.fit_resample(X_train , y_train)\n",
    "# Define objective\n",
    "objective = Objective(X_train, X_val, y_train, y_val, val_race, equailized_odds)\n",
    "#objective = Objective(X_train_resampled, X_val, y_train_resampled, y_val, val_race, metrics.f1_score)\n",
    "\n",
    "# Make a study to optimize the objective.\n",
    "study.optimize(objective, n_trials=100, n_jobs=-1, show_progress_bar=True)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "print(best_params)\n",
    "\n",
    "scaler = ColumnTransformer(\n",
    "    [('scaler', StandardScaler(), continuos_features)], remainder='passthrough')\n",
    "    \n",
    "whitebox_model = Pipeline(steps=[('scaler', scaler), ('clf', DecisionTreeClassifier(**best_params, random_state = 42))])\n",
    "# whitebox_model = Pipeline(steps=[('scaler', scaler), ('clf', DecisionTreeClassifier(random_state = 42))])\n",
    "\n",
    "whitebox_model.fit(train_processed, y_train)\n",
    "y_pred_whitebox = whitebox_model.predict(val_processed)\n",
    "y_pred_proba_whitebox = whitebox_model.predict_proba(val_processed)\n",
    "\n",
    "print(Counter(y_pred_whitebox))\n",
    "\n",
    "print(classification_report(y_val, y_pred_whitebox))\n",
    "\n",
    "print(equailized_odds(y_pred_whitebox, val_race, y_val, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'White': 36714,\n",
       "         'Black': 3401,\n",
       "         'Other': 1697,\n",
       "         'Asian': 1189,\n",
       "         'Hispanic': 4139,\n",
       "         'American Indian/Alaskan Native': 829})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(val_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "\n",
    "# Checking for correlation between variables\n",
    "from dython import nominal\n",
    "\n",
    "data_test = train_original.copy()\n",
    "\n",
    "# Encode the object as an enumerated type or categorical variable.\n",
    "data_test[categorical_features] = data_test[categorical_features].apply(lambda x : pd.factorize(x)[0])\n",
    "nominal.associations(data_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4168ca1474844f3f5fca761e685cf164ea20722acc5773b61bcc07160dedfd10"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
